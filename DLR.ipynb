{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a180e8",
   "metadata": {},
   "source": [
    "# Deep and Reinforcement Learning 2024/2025 (M.IA003), FEUP/FCUP\n",
    "\n",
    "## Deep Learning Project \n",
    "## **Develop deep learning discriminative and generative models, applied to the context of “deep fakes”**\n",
    "\n",
    "work done by:\n",
    "- Michal Kowalski up\n",
    "- Pedro Pereira up\n",
    "- Pedro Azevedo up201905966"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af449954",
   "metadata": {},
   "source": [
    "## 1.1) Import Necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad16ca3e-ad09-48f2-8d19-596118d1d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2386fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset directories\n",
    "data_dir = \"data\"\n",
    "real_dir = os.path.join(data_dir, \"real\")\n",
    "fake_dir = os.path.join(data_dir, \"fake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382a7090",
   "metadata": {},
   "source": [
    "## 1.2) Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ee9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _eda import base_stats\n",
    "\n",
    "base_stats(real_dir, fake_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e342df",
   "metadata": {},
   "source": [
    "## 1.3) File Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _preprocess import standardize_files\n",
    "\n",
    "standardize_files('data/real', (128, 128), '128')\n",
    "standardize_files('data/fake', (128, 128), '128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dir = os.path.join(data_dir, \"real_normalized_128\")\n",
    "fake_dir = os.path.join(data_dir, \"fake_normalized_128\")\n",
    "base_stats(real_dir, fake_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254ce207",
   "metadata": {},
   "source": [
    "## 1.4) Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _model import build_gan, train_gan\n",
    "\n",
    "d, g, gan = build_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "\n",
    "batch_size = 256\n",
    "# Get all image file paths\n",
    "image_paths = glob.glob(\"./data/real_normalized_128/*.jpg\")\n",
    "# Limit to 5,000 images\n",
    "# image_paths = image_paths[:5000]\n",
    "\n",
    "\n",
    "# Define the preprocessing function\n",
    "def load_and_preprocess(image_path):\n",
    "    # Read the image file\n",
    "    image = tf.io.read_file(image_path)\n",
    "\n",
    "    # Decode the JPEG image\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    # Normalize the image to the range [-1, 1]\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1.0\n",
    "\n",
    "    return image\n",
    "\n",
    "# Create the dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size//2, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# # Inspect the dataset\n",
    "\n",
    "batches = dataset.take(39)\n",
    "for batch in batches:\n",
    "    print(\"Batch shape:\", batch.shape)  # Should be (64, 128, 128, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e78cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(dataset, d, g, gan, epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ebe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.save('my_gan.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "saved_model = load_model('./my_gan.keras')\n",
    "saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e602bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = saved_model.layers[1]\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = saved_model.layers[2]\n",
    "gan = saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95622dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(dataset, d, g, gan, epochs=395, batch_size=256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
