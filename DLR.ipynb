{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a180e8",
   "metadata": {},
   "source": [
    "# Deep and Reinforcement Learning 2024/2025 (M.IA003), FEUP/FCUP\n",
    "\n",
    "## Deep Learning Project \n",
    "## **Develop deep learning discriminative and generative models, applied to the context of “deep fakes”**\n",
    "\n",
    "work done by:\n",
    "- Michal Kowalski up\n",
    "- Pedro Pereira up201708807\n",
    "- Pedro Azevedo up201905966"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af449954",
   "metadata": {},
   "source": [
    "## 1.1) Import Necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad16ca3e-ad09-48f2-8d19-596118d1d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from _model import *\n",
    "from tensorflow.keras.models import load_model\n",
    "import json\n",
    "\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2386fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset directories\n",
    "data_dir = \"data\"\n",
    "real_dir = os.path.join(data_dir, \"real\")\n",
    "fake_dir = os.path.join(data_dir, \"fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7149be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/celeba\"\n",
    "real_dir = os.path.join(data_dir, \"img_align_celeba\")\n",
    "\n",
    "# import tensorflow_datasets as tfds \n",
    "\n",
    "# celeba_builder = tfds.builder('celeb_a')\n",
    "# celeba_builder.download_and_prepare(download_dir=data_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382a7090",
   "metadata": {},
   "source": [
    "## 1.2) Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ee9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _eda import base_stats\n",
    "\n",
    "base_stats(real_dir, fake_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e342df",
   "metadata": {},
   "source": [
    "## 1.3) File Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _preprocess import standardize_files\n",
    "\n",
    "standardize_files('data/inpainting', (64, 64), '64')\n",
    "standardize_files('data/text2img', (64, 64), '64')\n",
    "# standardize_files('data/fake', (64, 64), '64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dir = os.path.join(data_dir, \"real_normalized_64\")\n",
    "fake_dir = os.path.join(data_dir, \"fake_normalized_64\")\n",
    "base_stats(real_dir, fake_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254ce207",
   "metadata": {},
   "source": [
    "## 1.4) Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = build_gan(label_smoothing=True, wgan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 256\n",
    "# Get all image file paths\n",
    "\n",
    "def save_paths(path_list, fname):\n",
    "    with open(fname, \"w\") as final:\n",
    "\t    json.dump(path_list, final)\n",
    "\n",
    "# Define the preprocessing function\n",
    "def load_and_preprocess(image_path):\n",
    "    # Read the image file\n",
    "    image = tf.io.read_file(image_path)\n",
    "\n",
    "    # Decode the JPEG image\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    # Normalize the image to the range [-1, 1]\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1.0\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_paths(train_file, test_file):\n",
    "    with open(train_file, \"r\") as train:\n",
    "\t    train_paths = json.load(train)\n",
    "    with open(test_file, \"r\") as test:\n",
    "\t    test_paths = json.load(test)\n",
    "    return train_paths, test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad0860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_paths = glob.glob(\"./data/celeba/img_align_celeba_normalized_64/*.jpg\")\n",
    "# train_paths = image_paths[:150000]\n",
    "# test_paths = image_paths[150000:]\n",
    "# save_paths(train_paths, 'train.json')\n",
    "# save_paths(test_paths, 'test.json')\n",
    "\n",
    "image_paths = glob.glob(\"./data/real_normalized_64/*.jpg\")\n",
    "\n",
    "#train_paths, test_paths = load_paths('./train.json', './test.json')\n",
    "\n",
    "# Create the dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size//2, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses, e_losses = train_gan(gan, dataset, epochs=40, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ebe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.save('celeba_wgan.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_d_losses = [float(x) for x in d_losses]\n",
    "final_g_losses = [float(x) for x in e_losses]\n",
    "with open('d_losses.json', \"w\") as f:\n",
    "    json.dump(final_d_losses, f)\n",
    "\n",
    "with open('g_losses.json', \"w\") as f:\n",
    "    json.dump(final_g_losses, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aae1f0",
   "metadata": {},
   "source": [
    "# 1.5) Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = keras.models.load_model(\"celeba_wgan.keras\", custom_objects={\"GAN\": GAN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e73f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(generator):\n",
    "    noise = np.random.normal(0, 1, (1, LATENT_DIM))\n",
    "    gen_images = generator.predict(noise)\n",
    "    gen_images = (gen_images + 1) / 2  # Rescale images to [0,1]\n",
    "    plt.imshow(gen_images[0])\n",
    "    plt.show()\n",
    "\n",
    "generate_image(gan.generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a7c8c",
   "metadata": {},
   "source": [
    "# 1.6) Test Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be399c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_paths = glob.glob(\"./data/fake_normalized_64/*.jpg\")\n",
    "inpainting_paths = glob.glob(\"./data/inpainting_normalized_64/*.jpg\")\n",
    "text2img_paths = glob.glob(\"./data/text2img_normalized_64/*.jpg\")\n",
    "\n",
    "_, real_paths = load_paths('./train.json', './test.json')\n",
    "\n",
    "# Create the dataset\n",
    "dataset_real = tf.data.Dataset.from_tensor_slices(real_paths)\n",
    "dataset_real = dataset_real.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset_real = dataset_real.shuffle(buffer_size=1000).batch(batch_size//2, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "dataset_insight = tf.data.Dataset.from_tensor_slices(insight_paths)\n",
    "dataset_insight = dataset_insight.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset_insight = dataset_insight.shuffle(buffer_size=1000).batch(batch_size//2, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "dataset_inpainting = tf.data.Dataset.from_tensor_slices(inpainting_paths)\n",
    "dataset_inpainting = dataset_inpainting.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset_inpainting = dataset_inpainting.shuffle(buffer_size=1000).batch(batch_size//2, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "dataset_text2img = tf.data.Dataset.from_tensor_slices(text2img_paths)\n",
    "dataset_text2img = dataset_text2img.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset_text2img = dataset_text2img.shuffle(buffer_size=1000).batch(batch_size//2, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _fid import *\n",
    "\n",
    "def gen_experiments(dataset_real, dataset_insight, dataset_inpainting, dataset_text2img, batch_size, num_batches=10):\n",
    "    gen_fids = []\n",
    "    insight_fids = []\n",
    "    inpainting_fids = []\n",
    "    text2img_fids = []\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, LATENT_DIM))\n",
    "        gen_images = gan.generator.predict(noise)\n",
    "\n",
    "        real_images = next(iter(dataset_real.take(1)))[0].numpy()\n",
    "        real_images = real_images.astype(np.float32)\n",
    "\n",
    "        insight_images = next(iter(dataset_insight.take(1)))[0].numpy()\n",
    "        insight_images = insight_images.astype(np.float32)\n",
    "\n",
    "        inpainting_images = next(iter(dataset_inpainting.take(1)))[0].numpy()\n",
    "        inpainting_images = inpainting_images.astype(np.float32)\n",
    "\n",
    "        text2img_images = next(iter(dataset_text2img.take(1)))[0].numpy()\n",
    "        text2img_images = text2img_images.astype(np.float32)\n",
    "\n",
    "        gen_images = img_scaler(gen_images, (75,75,3))\n",
    "        real_images = img_scaler(real_images, (75,75,3))\n",
    "        insight_images = img_scaler(insight_images, (75, 75, 3))\n",
    "        inpainting_images = img_scaler(inpainting_images, (75, 75, 3))\n",
    "        text2img_images = img_scaler(text2img_images, (75, 75, 3))\n",
    "\n",
    "        gen_fid = calculate_fid(inception_model, gen_images, real_images)\n",
    "        gen_fids.append(gen_fid)\n",
    "\n",
    "        insight_fid = calculate_fid(inception_model, insight_images, real_images)\n",
    "        insight_fids.append(insight_fid)\n",
    "\n",
    "        inpainting_fid = calculate_fid(inception_model, inpainting_images, real_images)\n",
    "        inpainting_fids.append(inpainting_fid)\n",
    "\n",
    "        text2img_fid = calculate_fid(inception_model, text2img_images, real_images)\n",
    "        text2img_fids.append(text2img_fid)\n",
    "\n",
    "    return np.mean(gen_fids), gen_fids, np.mean(insight_fids), insight_fids, np.mean(inpainting_fids), inpainting_fids, np.mean(text2img_fids), text2img_fids\n",
    "\n",
    "mean_gen, gen_fids, mean_ins, ins_fids, mean_inp, inp_fids, mean_t2i, t2i_fids = gen_experiments(dataset_real, dataset_insight, dataset_inpainting, dataset_text2img, batch_size//2, num_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_t2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f0aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
