{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a180e8",
   "metadata": {},
   "source": [
    "# Deep and Reinforcement Learning 2024/2025 (M.IA003), FEUP/FCUP\n",
    "\n",
    "## Deep Learning Project \n",
    "## **Develop deep learning discriminative and generative models, applied to the context of “deep fakes”**\n",
    "\n",
    "work done by:\n",
    "- Michal Kowalski up\n",
    "- Pedro Pereira up\n",
    "- Pedro Azevedo up201905966"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af449954",
   "metadata": {},
   "source": [
    "## 1.1) Import Necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad16ca3e-ad09-48f2-8d19-596118d1d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from _model import build_gan, train_gan, train_step\n",
    "from tensorflow.keras.models import load_model\n",
    "import json\n",
    "\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2386fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset directories\n",
    "data_dir = \"data\"\n",
    "real_dir = os.path.join(data_dir, \"real\")\n",
    "fake_dir = os.path.join(data_dir, \"fake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382a7090",
   "metadata": {},
   "source": [
    "## 1.2) Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ee9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _eda import base_stats\n",
    "\n",
    "base_stats(real_dir, fake_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e342df",
   "metadata": {},
   "source": [
    "## 1.3) File Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _preprocess import standardize_files\n",
    "\n",
    "standardize_files('data/real', (64, 64), '64')\n",
    "standardize_files('data/fake', (64, 64), '64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dir = os.path.join(data_dir, \"real_normalized_64\")\n",
    "fake_dir = os.path.join(data_dir, \"fake_normalized_64\")\n",
    "base_stats(real_dir, fake_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254ce207",
   "metadata": {},
   "source": [
    "## 1.4) Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d, g, do, go = build_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 256\n",
    "# Get all image file paths\n",
    "\n",
    "def save_paths(path_list, fname):\n",
    "    with open(fname, \"w\") as final:\n",
    "\t    json.dump(path_list, final)\n",
    "\n",
    "# Define the preprocessing function\n",
    "def load_and_preprocess(image_path):\n",
    "    # Read the image file\n",
    "    image = tf.io.read_file(image_path)\n",
    "\n",
    "    # Decode the JPEG image\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    # Normalize the image to the range [-1, 1]\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1.0\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_paths(train_file, test_file):\n",
    "    with open(train_file, \"r\") as train:\n",
    "\t    train_paths = json.load(train)\n",
    "    with open(test_file, \"r\") as test:\n",
    "\t    test_paths = json.load(test)\n",
    "    return train_paths, test_paths\n",
    "\n",
    "# image_paths = glob.glob(\"./data/real_normalized_64/*.jpg\")\n",
    "# train_paths = image_paths[:25000]\n",
    "# test_paths = image_paths[25000:]\n",
    "# save_paths(train_paths, 'train.json')\n",
    "# save_paths(test_paths, 'test.json')\n",
    "\n",
    "train_paths, test_paths = load_paths('./train.json', './test.json')\n",
    "\n",
    "# Create the dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size//2, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c380bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses, e_losses = train_gan(dataset, d, g, do, go, epochs=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ebe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.save('my_generator.keras')\n",
    "d.save('my_discriminator.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_d_losses = [float(x) for x in d_losses]\n",
    "final_g_losses = [float(x) for x in e_losses]\n",
    "with open('d_losses.json', \"w\") as f:\n",
    "    json.dump(final_d_losses, f)\n",
    "\n",
    "with open('g_losses.json', \"w\") as f:\n",
    "    json.dump(final_g_losses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_model('./my_discriminator200.keras')\n",
    "g = load_model('./my_generator200.keras')\n",
    "\n",
    "go = tf.keras.optimizers.Adam(1e-4)\n",
    "do = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e602bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = saved_model.layers[1]\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = saved_model.layers[2]\n",
    "gan = saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95622dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses, e_losses = train_gan(dataset, d, g, do, go, epochs=200, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
