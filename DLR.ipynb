{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a180e8",
   "metadata": {},
   "source": [
    "# Deep and Reinforcement Learning 2024/2025 (M.IA003), FEUP/FCUP\n",
    "\n",
    "## Deep Learning Project \n",
    "## **Develop deep learning discriminative and generative models, applied to the context of “deep fakes”**\n",
    "\n",
    "work done by:\n",
    "- Michal Kowalski up\n",
    "- Pedro Pereira up\n",
    "- Pedro Azevedo up201905966"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af449954",
   "metadata": {},
   "source": [
    "## 1.1) Import Necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad16ca3e-ad09-48f2-8d19-596118d1d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from _model import *\n",
    "from tensorflow.keras.models import load_model\n",
    "import json\n",
    "\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2386fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset directories\n",
    "data_dir = \"data\"\n",
    "real_dir = os.path.join(data_dir, \"real\")\n",
    "fake_dir = os.path.join(data_dir, \"fake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382a7090",
   "metadata": {},
   "source": [
    "## 1.2) Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ee9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _eda import base_stats\n",
    "\n",
    "base_stats(real_dir, fake_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e342df",
   "metadata": {},
   "source": [
    "## 1.3) File Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _preprocess import standardize_files\n",
    "\n",
    "standardize_files('data/real', (64, 64), '64')\n",
    "standardize_files('data/fake', (64, 64), '64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dir = os.path.join(data_dir, \"real_normalized_64\")\n",
    "fake_dir = os.path.join(data_dir, \"fake_normalized_64\")\n",
    "base_stats(real_dir, fake_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254ce207",
   "metadata": {},
   "source": [
    "## 1.4) Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = build_gan(d_lr=1e-5, label_smoothing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 256\n",
    "# Get all image file paths\n",
    "\n",
    "def save_paths(path_list, fname):\n",
    "    with open(fname, \"w\") as final:\n",
    "\t    json.dump(path_list, final)\n",
    "\n",
    "# Define the preprocessing function\n",
    "def load_and_preprocess(image_path):\n",
    "    # Read the image file\n",
    "    image = tf.io.read_file(image_path)\n",
    "\n",
    "    # Decode the JPEG image\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    # Normalize the image to the range [-1, 1]\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1.0\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_paths(train_file, test_file):\n",
    "    with open(train_file, \"r\") as train:\n",
    "\t    train_paths = json.load(train)\n",
    "    with open(test_file, \"r\") as test:\n",
    "\t    test_paths = json.load(test)\n",
    "    return train_paths, test_paths\n",
    "\n",
    "# image_paths = glob.glob(\"./data/real_normalized_64/*.jpg\")\n",
    "# train_paths = image_paths[:25000]\n",
    "# test_paths = image_paths[25000:]\n",
    "# save_paths(train_paths, 'train.json')\n",
    "# save_paths(test_paths, 'test.json')\n",
    "\n",
    "train_paths, test_paths = load_paths('./train.json', './test.json')\n",
    "\n",
    "# Create the dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size//2, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses, e_losses = train_gan(gan, dataset, epochs=200, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ebe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.save('ls_dlr.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_d_losses = [float(x) for x in d_losses]\n",
    "final_g_losses = [float(x) for x in e_losses]\n",
    "with open('d_losses.json', \"w\") as f:\n",
    "    json.dump(final_d_losses, f)\n",
    "\n",
    "with open('g_losses.json', \"w\") as f:\n",
    "    json.dump(final_g_losses, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aae1f0",
   "metadata": {},
   "source": [
    "# 1.5) Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = keras.models.load_model(\"ls_dlr.keras\", custom_objects={\"GAN\": GAN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e73f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(generator):\n",
    "    noise = np.random.normal(0, 1, (1, LATENT_DIM))\n",
    "    gen_images = generator.predict(noise)\n",
    "    gen_images = (gen_images + 1) / 2  # Rescale images to [0,1]\n",
    "    plt.imshow(gen_images[0])\n",
    "    plt.show()\n",
    "\n",
    "generate_image(gan.generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _fid import *\n",
    "\n",
    "noise = np.random.normal(0, 1, (batch_size//2, LATENT_DIM))\n",
    "gen_images = gan.generator.predict(noise)\n",
    "real_images = dataset.take(1)\n",
    "\n",
    "real_images = next(iter(dataset.take(1)))[0].numpy()\n",
    "\n",
    "# Ensure correct dtype for skimage\n",
    "real_images = real_images.astype(np.float32)\n",
    "\n",
    "gen_images = img_scaler(gen_images, (75,75,3))\n",
    "real_images = img_scaler(real_images, (75,75,3))\n",
    "\n",
    "calculate_fid(inception_model, gen_images, real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95622dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses, e_losses = train_gan(dataset, d, g, do, go, epochs=200, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
