{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a180e8",
   "metadata": {},
   "source": [
    "# Deep and Reinforcement Learning 2024/2025 (M.IA003), FEUP/FCUP\n",
    "\n",
    "## Deep Learning Project \n",
    "## **Develop deep learning discriminative and generative models, applied to the context of “deep fakes”**\n",
    "\n",
    "work done by:\n",
    "- Michal Kowalski up\n",
    "- Pedro Pereira up\n",
    "- Pedro Azevedo up201905966"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af449954",
   "metadata": {},
   "source": [
    "## 1.1) Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad16ca3e-ad09-48f2-8d19-596118d1d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b2386fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset directories\n",
    "data_dir = \"data\"\n",
    "real_dir = os.path.join(data_dir, \"real\")\n",
    "fake_dir = os.path.join(data_dir, \"fake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382a7090",
   "metadata": {},
   "source": [
    "## 1.2) Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e05ee9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real Images Summary:\n",
      "Total images: 30000\n",
      "Formats: Counter({'JPEG': 28952, 'PNG': 1005, 'GIF': 36, 'MPO': 7})\n",
      "Color Modes: Counter({'RGB': 26445, 'L': 2840, 'RGBA': 664, 'P': 40, 'LA': 11})\n",
      "Top 5 Sizes: [((440, 660), 1469), ((440, 587), 959), ((440, 293), 688), ((440, 330), 579), ((440, 440), 272)]\n",
      "\n",
      "Fake Images Summary:\n",
      "Total images: 29998\n",
      "Formats: Counter({'JPEG': 29998})\n",
      "Color Modes: Counter({'RGB': 29998})\n",
      "Top 5 Sizes: [((512, 512), 29998)]\n"
     ]
    }
   ],
   "source": [
    "from _eda import base_stats\n",
    "\n",
    "base_stats(real_dir, fake_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e342df",
   "metadata": {},
   "source": [
    "## 1.3) File Standardization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1386896d",
   "metadata": {},
   "source": [
    "Create the prepared data dir to introduce all standardize files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730e1751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists\n"
     ]
    }
   ],
   "source": [
    "prepared_data_dir = 'prepared_data'\n",
    "if not os.path.exists(prepared_data_dir):\n",
    "    os.makedirs(prepared_data_dir)\n",
    "else:\n",
    "    print(\"Directory already exists\")\n",
    "    response = input(\"Press y to continue and n to cancel: \")\n",
    "    if response == 'y':\n",
    "        os.remove(prepared_data_dir)\n",
    "        os.makedirs(prepared_data_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c0d6d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization complete. Images saved in 'prepared_data/real'.\n",
      "Normalization complete. Images saved in 'prepared_data/fake'.\n"
     ]
    }
   ],
   "source": [
    "from _preprocess import standardize_files\n",
    "\n",
    "standardize_files( str(data_dir+'/real'), (512, 512), str(prepared_data_dir+'/real'))\n",
    "standardize_files( str(data_dir+'/fake'), (512, 512), str(prepared_data_dir+'/fake'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e97e9f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real Images Summary:\n",
      "Total images: 30000\n",
      "Formats: Counter({'JPEG': 30000})\n",
      "Color Modes: Counter({'RGB': 30000})\n",
      "Top 5 Sizes: [((512, 512), 30000)]\n",
      "\n",
      "Fake Images Summary:\n",
      "Total images: 29998\n",
      "Formats: Counter({'JPEG': 29998})\n",
      "Color Modes: Counter({'RGB': 29998})\n",
      "Top 5 Sizes: [((512, 512), 29998)]\n"
     ]
    }
   ],
   "source": [
    "real_dir = os.path.join(prepared_data_dir, \"real\")\n",
    "fake_dir = os.path.join(prepared_data_dir, \"fake\")\n",
    "base_stats(real_dir, fake_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf676b",
   "metadata": {},
   "source": [
    "# 1.4) Create a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5c3f3",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b25758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0206c5",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35b7721c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "890\n"
     ]
    }
   ],
   "source": [
    "img_height = 512\n",
    "img_width = 512\n",
    "\n",
    "validation_split = 0.3\n",
    "seed = random.randint(1,1000)\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d07efb",
   "metadata": {},
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0377e153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59998 files belonging to 2 classes.\n",
      "Using 41999 files for training.\n",
      "Found 59998 files belonging to 2 classes.\n",
      "Using 17999 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  prepared_data_dir,\n",
    "  validation_split=validation_split,\n",
    "  subset=\"training\",\n",
    "  seed=seed,\n",
    "  image_size=(img_height, img_width))\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  prepared_data_dir,\n",
    "  validation_split=validation_split,\n",
    "  subset=\"validation\",\n",
    "  seed=seed,\n",
    "  image_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf11f76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fake', 'real']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
